{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from random import shuffle\n",
    "\n",
    "# web scraping libraries\n",
    "from pynyt import NYTArticleAPIObject\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# NLP libraries\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "\n",
    "#plotting libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1987.to_pickle('df_1987.pickle')\n",
    "df_2017.to_pickle('df_2017.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1987 = pd.read_pickle('df_1987.pickle')\n",
    "df_2017 = pd.read_pickle('df_2017.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever I visit home, I find a few hours to leaf through my parents' collection of old ('80s and '90s) National Geographic magazines. Although many of the magazine's advertisements are good for a quick laugh, I'm most fascinated by the longform articles—ambitious, sweeping stories spun across thirty pages or more, the product of many months of work for a writer-photographer team. The best of these articles succeed in distilling the essence of a place or culture into an hour's worth of text and images.\n",
    "\n",
    "Reading these magazines has led to my developing an interest in the evolution of journalism. Over the years, these lengthy expositions seem to have fallen out of favor, replaced by shorter, more specific articles; in my mind, articles of over thirty pages are definitely a thing of the past. As a newcomer to the field of data science, I thought it would be interesting to verify my intuition using real data. I set out to obtain articles from the past and present, with the goal of making comparisons and determining if enough difference existed to build a predictive model - could a relatively simple model predict whether an article was written recently or not-so-recently?\n",
    "\n",
    "Unfortunately, accessing National Geographic backlogs online requires a paid subscription. I quickly found an alternative in the New York Times, which allows free access (with daily limits) to its archives via the [Times Developer Network](https://developer.nytimes.com/). A variety of web APIs are provided, a few of which are very useful for combing lots of article data - I chose the Article Search API, which allows the user to narrow down a query using all of the extensive metadata fields. (An Article Search API key can be obtained at the above link.) A couple of Python wrappers do exist for the Article Search API, but none of them are actively maintained and I figured writing my own would be a good exercise, and a good opportunity to learn about the [requests](http://docs.python-requests.org/en/master/) library, among other things. My wrapper class can be found in pynyt.py—it worked very well for the purposes of this project, although there does seem to be a non-deterministic bug when making too many queries in a single notebook block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    }
   ],
   "source": [
    "miner = NYTArticleAPIObject('my api key is a secret! get your own! mine mine mine')\n",
    "\n",
    "miner.get_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_usage()` returns the number of API calls permitted for the day, the limit being 1000. (Calling the function also consumes a precious API call—a truly unfortunate necessity.) There are more limitations: a query can only return up to 1000 article results; if a query is too broad, results past the thousandth article will be cut off. Additionally, the results are returned 10 at a time, across up to 100 pages, and grabbing each page requires an API call.\n",
    "\n",
    "For this project, these API limitations are inconsequential. I decided to grab 2,000 articles each from 2017 and 1987 - hopefully plenty for analysis and modeling, with more than half of my all-important API calls to spare. The Times publishes a wide variety of written material—in addition to traditional articles, material types include editorials, op-eds, columns, interviews, obituaries, and so forth. I wanted to limit this analysis to what I most readily associate with the New York Times: news stories written by Times reporters. The below queries pull 2,000 Times-sourced news articles each from the relevant years. Within a given year's results, 1,000 articles are from the foreign news desk and 1,000 are from the national news desk. This limitation is imposed with the additional goal of obtaining articles from 1987 and 2017 written about broadly similar topics (in order to focus the analysis and modeling on the style and conventions of the journalism itself, rather than the subject matter).\n",
    "\n",
    "The code is split into four blocks to avoid the aforementioned bug, the exact cause of which I have yet to determine. The results are returned as a list of dictionaries, each entry being a page of query results (i.e. data for up to 10 articles). The responses are supposed to be ordered by relevancy, although in actuality I think all matching results are returned in order of recency of publication. Even in that case, 2,000 articles for a given year should make for a week or two's worth of news from around the world, which ought to be a diverse enough dataset for this purpose.\n",
    "\n",
    "(If you're running this yourself, you might want to set verbose=True in the function call to see the progress—each call will pull 100 pages of article metadata.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_1987 = miner.query(fq = {'source': 'New York Times',\n",
    "                                  'news_desk': 'Foreign',\n",
    "                                  'type_of_material': 'News'},\n",
    "                            begin_date = 19870101,\n",
    "                            end_date = 19871231,\n",
    "                            halt_overflow = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_1987 += miner.query(fq = {'source': 'New York Times',\n",
    "                                 'news_desk': 'National',\n",
    "                                 'type_of_material': 'News'},\n",
    "                            begin_date = 19870101,\n",
    "                            end_date = 19871231,\n",
    "                            halt_overflow = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_2017 = miner.query(fq = {'source': 'New York Times',\n",
    "                                 'news_desk': 'Foreign',\n",
    "                                 'type_of_material': 'News'},\n",
    "                           begin_date = 20170101,\n",
    "                           halt_overflow = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_2017 += miner.query(fq = {'source': 'New York Times',\n",
    "                                  'news_desk': 'National',\n",
    "                                  'type_of_material': 'News'},\n",
    "                            begin_date = 20170101,\n",
    "                            halt_overflow = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As illustrated [here](https://developer.nytimes.com/article_search_v2.json#/README) (scroll down to example responses), all sorts of metadata is returned, much of which I didn't think I would need to use. I was most interested in approaching this as a text classification study, so for a given article, all I really needed was the body of text and perhaps the headline and date. As it turned out, the responses do not contain the actual text of each article, so I also ended up having to grab each article's URL for scraping. These fields were loaded into another list of dictionaries for easy conversion to a Pandas dataframe shortly down the line.\n",
    "\n",
    "(In the below function, I accidentally pull the source of the article as well, which is unneccessary given that the query results were limited to those from the New York Times.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def results_to_list(results): # not a great name - results is a list of dicts too\n",
    "    results_list = []\n",
    "    for i in range(len(results)):\n",
    "        for article in results[i]['response']['docs']:\n",
    "            source = ''\n",
    "            if 'source' in article:\n",
    "                source = article['source']\n",
    "            results_list.append({'date': article['pub_date'],\n",
    "                            'headline': article['headline']['main'],\n",
    "                            'web_url': article['web_url'],\n",
    "                            'source': source})\n",
    "    return results_list\n",
    "\n",
    "list_1987 = results_to_list(results_1987)\n",
    "list_2017 = results_to_list(results_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('list_1987.pickle', 'rb') as f:\n",
    "    list_1987 = pickle.load(f)\n",
    "with open('list_2017.pickle', 'rb') as f:\n",
    "    list_2017 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>source</th>\n",
       "      <th>web_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987-12-31T00:00:00Z</td>\n",
       "      <td>The Hills Are Not Alive With the Swoosh of Skis</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>https://www.nytimes.com/1987/12/31/world/the-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987-12-31T00:00:00Z</td>\n",
       "      <td>Kabul Says a Convoy Breaks Siege of a City</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>https://www.nytimes.com/1987/12/31/world/kabul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987-12-31T00:00:00Z</td>\n",
       "      <td>Al Ghourayib Journal; And if the Nile Dries Up...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>https://www.nytimes.com/1987/12/31/world/al-gh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987-12-31T00:00:00Z</td>\n",
       "      <td>Salvador Court Frees 2 Killers of Americans</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>https://www.nytimes.com/1987/12/31/world/salva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987-12-31T00:00:00Z</td>\n",
       "      <td>Rights Group Invited to Moscow For Week of Tal...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>https://www.nytimes.com/1987/12/31/world/right...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date                                           headline  \\\n",
       "0  1987-12-31T00:00:00Z    The Hills Are Not Alive With the Swoosh of Skis   \n",
       "1  1987-12-31T00:00:00Z         Kabul Says a Convoy Breaks Siege of a City   \n",
       "2  1987-12-31T00:00:00Z  Al Ghourayib Journal; And if the Nile Dries Up...   \n",
       "3  1987-12-31T00:00:00Z        Salvador Court Frees 2 Killers of Americans   \n",
       "4  1987-12-31T00:00:00Z  Rights Group Invited to Moscow For Week of Tal...   \n",
       "\n",
       "               source                                            web_url  \n",
       "0  The New York Times  https://www.nytimes.com/1987/12/31/world/the-h...  \n",
       "1  The New York Times  https://www.nytimes.com/1987/12/31/world/kabul...  \n",
       "2  The New York Times  https://www.nytimes.com/1987/12/31/world/al-gh...  \n",
       "3  The New York Times  https://www.nytimes.com/1987/12/31/world/salva...  \n",
       "4  The New York Times  https://www.nytimes.com/1987/12/31/world/right...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1987 = pd.DataFrame(list_1987)\n",
    "df_2017 = pd.DataFrame(list_2017)\n",
    "\n",
    "df_1987.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data from the API queries loaded into dataframes, the next step is to scrape the text from each article and add it to the dataframes. This can be accomplished by using BeautifulSoup and inspecting New York Times article source code to find the right tags to search for. Looking at a few articles from 1987 and 2017, it looks like the text body is contained in paragraph tags with `itemprop='articleBody'` for 1987 articles and `class_='story-body-text story-content'` for 2017 articles. I'm not sure if these were uniform conventions for the given years, and so the scraping code makes sure to check for empty or very short strings (the result of a failure to find the right tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "df_1987['text'] = \"\"\n",
    "df_2017['text'] = \"\"\n",
    "\n",
    "def get_text(df):\n",
    "    session = requests.Session()\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if i % 100 == 0:\n",
    "            print('Processing url', i)\n",
    "        url = df.iloc[i]['web_url']\n",
    "        req = session.get(url)\n",
    "        soup = BeautifulSoup(req.text, \"html5lib\")\n",
    "        # paragraphs = soup.find_all('p', itemprop = 'articleBody') # 1987 articles\n",
    "        paragraphs = soup.find_all('p', class_='story-body-text story-content') # 2017 articles\n",
    "\n",
    "        txt = ''\n",
    "        for p in paragraphs: # newlines for nice printing + paragraph analysis\n",
    "            # txt += p.getText() # 1987 - newlines already written in\n",
    "            txt += p.getText() + \"\\n\" # 2017\n",
    "        df.set_value(i, 'text', txt)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# df_1987 = get_text(df_1987)\n",
    "df_2017 = get_text(df_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987\n",
      "2017\n",
      "Length 0 at URL 896: https://www.nytimes.com/2017/06/16/world/canada/the-times-in-canada.html\n",
      "Length 0 at URL 1264: https://www.nytimes.com/2017/07/21/us/politics/trump-communications-scaramucci-sanders.html\n",
      "Length 0 at URL 1340: https://www.nytimes.com/2017/07/17/us/politics/trump-laws-bills.html\n",
      "Length 0 at URL 1376: https://www.nytimes.com/2017/07/14/us/how-poems-inspire-pictures.html\n",
      "Length 0 at URL 1398: https://www.nytimes.com/2017/07/12/us/politics/trump-russia-election-meeting.html\n",
      "Length 0 at URL 1442: https://www.nytimes.com/2017/07/10/us/western-wildfires.html\n",
      "Length 0 at URL 1472: https://www.nytimes.com/2017/07/07/us/politics/senate-hobbies.html\n",
      "Length 0 at URL 1536: https://www.nytimes.com/2017/06/30/us/handmaids-protests-abortion.html\n",
      "Length 0 at URL 1612: https://www.nytimes.com/2017/06/25/us/extreme-heat-scorches-southern-arizona.html\n"
     ]
    }
   ],
   "source": [
    "def get_problem_indices(df):\n",
    "    problem_indices = []\n",
    "    for idx, article in df.iterrows():\n",
    "        length = len(article['text'])\n",
    "        if length < 100:\n",
    "            print('Length {} at URL {}: {}'.format(length, idx, article['web_url']))\n",
    "            problem_indices.append(idx)\n",
    "    return problem_indices\n",
    "\n",
    "print('1987')\n",
    "problem_indices_1987 = get_problem_indices(df_1987)\n",
    "print('2017')\n",
    "problem_indices_2017 = get_problem_indices(df_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No problematic articles are encountered in the 1987 dataframe, but get_text() fails to obtain any text for several 2017 articles, as seen in the output above.\n",
    "\n",
    "Looking at the problematic articles, it's apparent that the issue arises from the articles possessing an unusual layout, perhaps for web-only presentation. The text is contained in paragraph tags with a very long class name, which will not be reproduced here! The articles are re-scraped using said class name and the lengths of each new text is printed to check whether the class name applies to all of the problematic articles. A reasonable number of characters are thus found for each of the articles, so it looks like no further fixes are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2919\n",
      "4569\n",
      "14312\n",
      "10545\n",
      "10371\n",
      "3891\n",
      "9564\n",
      "5032\n",
      "4024\n"
     ]
    }
   ],
   "source": [
    "session = requests.Session()\n",
    "p_class = \"Paragraph-paragraph--2eXNE OakElement-paragraph--2e5h2 OakElement-left--2eGEj OakElement-toneFeature--uJSyt OakParagraph-headerHasNoLedeMedia--1Uoi7\"\n",
    "for idx in problem_indices_2017:\n",
    "    url = df_2017.iloc[idx]['web_url']\n",
    "    req = session.get(url)\n",
    "    soup = BeautifulSoup(req.text, 'html5lib')\n",
    "    paragraphs = soup.find_all('p', class_ = p_class)\n",
    "\n",
    "    txt = ''\n",
    "    for p in paragraphs:\n",
    "        txt += p.getText() + \"\\n\" # 2017\n",
    "        \n",
    "    print(len(txt))\n",
    "    \n",
    "    df_2017.set_value(idx, 'text', txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the articles have been scraped, one of the initial questions—whether article length has changed over time—can be answered. This code adds columns to the dataframe for article length in words, as well as headline length, for good measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>headline_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.00000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>603.60700</td>\n",
       "      <td>7.381000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>326.77331</td>\n",
       "      <td>2.433269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>324.00000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>631.00000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>857.25000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1361.00000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           length  headline_length\n",
       "count  2000.00000      2000.000000\n",
       "mean    603.60700         7.381000\n",
       "std     326.77331         2.433269\n",
       "min      27.00000         1.000000\n",
       "25%     324.00000         6.000000\n",
       "50%     631.00000         7.000000\n",
       "75%     857.25000         9.000000\n",
       "max    1361.00000        25.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>headline_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>965.439500</td>\n",
       "      <td>9.963500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>445.391875</td>\n",
       "      <td>1.880674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>628.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>937.500000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1240.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4569.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length  headline_length\n",
       "count  2000.000000      2000.000000\n",
       "mean    965.439500         9.963500\n",
       "std     445.391875         1.880674\n",
       "min      41.000000         3.000000\n",
       "25%     628.000000         9.000000\n",
       "50%     937.500000        10.000000\n",
       "75%    1240.000000        11.000000\n",
       "max    4569.000000        19.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_length(text):\n",
    "    return len(text.split())\n",
    "\n",
    "df_1987['length'] = df_1987['text'].map(get_length)\n",
    "df_2017['length'] = df_2017['text'].map(get_length)\n",
    "df_1987['headline_length'] = df_1987['headline'].map(get_length)\n",
    "df_2017['headline_length'] = df_2017['headline'].map(get_length)\n",
    "display(df_1987.describe())\n",
    "display(df_2017.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are quite suprising—article and headline length are both significantly longer today than in 1987, on average. Plotting the distributions might uncover some further insights. We can start with article length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAEYCAYAAADPrtzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nATkfr+sElAUqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116ee8cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_subplots(series, axis, my_color):\n",
    "    axis.hist(series, bins=np.linspace(0, 5000, 101)) # bucket size of 50\n",
    "    axis.set_ylim(0, 160)\n",
    "    axis.set_xlim(0, 5000)\n",
    "    axis.grid()\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.set_size_inches(14, 4)\n",
    "\n",
    "plot_subplots(df_1987['length'], axs[0], 'b')\n",
    "plot_subplots(df_2017['length'], axs[1], 'r')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions are quite different. The 1987 article length histogram seems roughly bimodal, with many of the articles being either very short (under 250 words) or of moderate length (500-1000 words). Relatively few articles of length greater than 1000 words are published. On the other hand, the distribution for 2017 appears to be closer to normal, albeit more strongly right-skewed. Articles below 250 words in length are nearly completely absent, and half or so of the articles appear to be at least 1000 words long.\n",
    "\n",
    "The abundance of very short articles in the 1987 dataset is quite interesting. [Here's](https://www.nytimes.com/1987/12/28/world/new-zealand-fire-kills-3.html) the shortest article of them all—just one sentence long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "New Zealand Fire Kills 3\n",
      "\n",
      "                    AUCKLAND, New Zealand, Dec. 27— \n",
      "                    Fire destroyed a hotel today and killed three children in the town of Taneatua, 150 miles south of Auckland, the police said.        \n"
     ]
    }
   ],
   "source": [
    "len_min_idx = df_1987['length'].argmin()\n",
    "print(df_1987.iloc[len_min_idx]['length'])\n",
    "print(df_1987.iloc[len_min_idx]['headline'])\n",
    "print(df_1987.iloc[len_min_idx]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why might the distributions be so different? One factor could be that some of the long articles from 2017 are web-only publications, free of restrictions on length imposed by the print newspaper format. Finding an easy explanation for the decline of very short articles is a bit more difficult. It seems reasonable to attribute this change to an evolution in the Times's underlying protocols over time—articles of just a few sentences have simply fallen out of favor.\n",
    "\n",
    "Similarly, we can plot the distributions for headline length. In this case, boxplots as well as histograms make for interesting representations of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAEYCAYAAADPrtzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAdOD/ACPoK6n687WQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x145ddeef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_subplots(series, axis, my_color):\n",
    "    axis.hist(series, bins=np.linspace(0, 25, 26)) # bucket size of 1\n",
    "    axis.set_ylim(0, 500)\n",
    "    axis.set_xlim(0, 25)\n",
    "    axis.grid()\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.set_size_inches(14, 4)\n",
    "\n",
    "plot_subplots(df_1987['headline_length'], axs[0], 'b')\n",
    "plot_subplots(df_2017['headline_length'], axs[1], 'r')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x113c5ea20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAATi/wFPTR8YMN2sgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113c5e518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_headlines = pd.concat([df_1987['headline_length'], df_2017['headline_length']],\n",
    "                                axis=1,\n",
    "                                keys=['1987', '2017'])\n",
    "\n",
    "combined_headlines.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the histogram distribution is significantly tighter for headlines written in the current year, further signified by the small interquartile ranges and abundance of outliers on both sides of the 2017 boxplot. The reduction in variability might indicate that headline writing is more standardized overall today than it was in 1987.\n",
    "\n",
    "Another feature of potential interest is the average sentence length in a given article. Splitting at every period might not be the most intelligent way to go about this task, given the likely prevalence of abbreviations in these articles. The [TextBlob library](https://textblob.readthedocs.io/en/dev/), which provides a simple API for common NLP tasks, has functionality for splitting a text into sentences, so it's worth trying it out here. (I eventually move on to using nltk for modeling purposes, but since this is a first foray into NLP, TextBlob serves as a good starting point.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1987</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.949195</td>\n",
       "      <td>27.821021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.259242</td>\n",
       "      <td>5.003114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.090909</td>\n",
       "      <td>9.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.063497</td>\n",
       "      <td>24.435619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.630604</td>\n",
       "      <td>27.482051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26.464493</td>\n",
       "      <td>30.924015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>57.500000</td>\n",
       "      <td>53.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1987         2017\n",
       "count  2000.000000  2000.000000\n",
       "mean     23.949195    27.821021\n",
       "std       4.259242     5.003114\n",
       "min       9.090909     9.175000\n",
       "25%      21.063497    24.435619\n",
       "50%      23.630604    27.482051\n",
       "75%      26.464493    30.924015\n",
       "max      57.500000    53.571429"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_mean_sentence_length(text):\n",
    "    sentences = TextBlob(text).sentences\n",
    "    lengths = []\n",
    "    for s in sentences:\n",
    "        lengths.append(len(s.words))\n",
    "    return sum(lengths) / len(lengths)\n",
    "\n",
    "df_1987['mean_sentence_length'] = df_1987['text'].map(get_mean_sentence_length)\n",
    "df_2017['mean_sentence_length'] = df_2017['text'].map(get_mean_sentence_length)\n",
    "\n",
    "combined_sentences = pd.concat([df_1987['mean_sentence_length'], df_2017['mean_sentence_length']],\n",
    "                                axis=1,\n",
    "                                keys=['1987', '2017'])\n",
    "\n",
    "display(combined_sentences.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the advent of longer articles, sentences have actually gotten longer, too. Plotting the distributions with a histogram might be interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAEYCAYAAADPrtzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117cf0eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_subplots(series, axis, my_color):\n",
    "    axis.hist(series, bins=np.linspace(0, 60, 31)) # bucket size of 2\n",
    "    axis.set_ylim(0, 410)\n",
    "    axis.set_xlim(0, 60)\n",
    "    axis.grid()\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.set_size_inches(14, 4)\n",
    "\n",
    "plot_subplots(df_1987['mean_sentence_length'], axs[0], 'b')\n",
    "plot_subplots(df_2017['mean_sentence_length'], axs[1], 'r')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the 2017 distribution is a little bit broader, perhaps indicating further stylistic freedoms in modern-day journalistic writing compared to the rigidities of old. This makes for an interesting contrast when compared to the decline in variation in headline lengths.\n",
    "\n",
    "Sentiment analysis is another avenue of exploration for comparing these sets of articles. The polarity (-1.0 to 1.0, negative to positive) and subjectivity (0.0 to 1.0, objective to subjective) of a text can be obtained easily using TextBlob's sentiment analyzer. The polarity and subjectivity can be added to the dataframes as with the previous measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def get_subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "df_1987['polarity'] = df_1987['text'].map(get_polarity)\n",
    "df_2017['polarity'] = df_2017['text'].map(get_polarity)\n",
    "\n",
    "df_1987['subjectivity'] = df_1987['text'].map(get_subjectivity)\n",
    "df_2017['subjectivity'] = df_2017['text'].map(get_subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.054308</td>\n",
       "      <td>0.373114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.073908</td>\n",
       "      <td>0.095442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.012960</td>\n",
       "      <td>0.325357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.055558</td>\n",
       "      <td>0.379736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.096405</td>\n",
       "      <td>0.428867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          polarity  subjectivity\n",
       "count  2000.000000   2000.000000\n",
       "mean      0.054308      0.373114\n",
       "std       0.073908      0.095442\n",
       "min      -0.500000      0.000000\n",
       "25%       0.012960      0.325357\n",
       "50%       0.055558      0.379736\n",
       "75%       0.096405      0.428867\n",
       "max       0.600000      1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1987[['polarity', 'subjectivity']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.056852</td>\n",
       "      <td>0.387228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.055530</td>\n",
       "      <td>0.063004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.198056</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.023458</td>\n",
       "      <td>0.349520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.058852</td>\n",
       "      <td>0.391664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.093797</td>\n",
       "      <td>0.427676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.594872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          polarity  subjectivity\n",
       "count  2000.000000   2000.000000\n",
       "mean      0.056852      0.387228\n",
       "std       0.055530      0.063004\n",
       "min      -0.198056      0.000000\n",
       "25%       0.023458      0.349520\n",
       "50%       0.058852      0.391664\n",
       "75%       0.093797      0.427676\n",
       "max       0.290000      0.594872"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017[['polarity', 'subjectivity']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These sentiment measures are actually very similar between the two groups. Subjectivity in particular is surprisingly high (~0.4); for a news source to be only moderately objective seems unintuitive. There also appear to be some wacky outliers, as the maximum subjectivity value of 1.0 in df_1987 indicates. We can try taking a look at that particular article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                    BURLINGTON, Vt., Dec. 19— \n",
      "                    Look USA, a distributor of French-made alpine ski bindings, is recalling 13 models to fix a defect that could cause the binding to release unexpectedly, the company said Friday.        \n",
      "                    Consumers were being asked to return the 30,000 bindings to authorized dealers for adjustment, a company spokesman said. The company had received complaints about the bindings but no injuries have been reported, he added.        \n",
      "                    The models being recalled are ZRC, ZR, ZP, ZL, ZRJ, X-9, X-7, X-5, XH, XF, XFL, XG, XGR.        \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "max_subj = df_1987['subjectivity'].argmax()\n",
    "te = (df_1987.iloc[max_subj]['text'])\n",
    "print(te)\n",
    "print(df_1987.iloc[max_subj]['subjectivity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevant article is quite short, which may contribute to the extreme value; nonetheless, nothing about the text itself seems amiss. If anything, the article appears to be quite objective. To explore further, the text is broken up into individual words and the TextBlob sentiment analyzer is used to compute the subjectivity of each individual word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0: {'ZL,', 'been', '30,000', 'about', 'Consumers', 'said', 'he', 'XGR.', 'bindings', 'added.', 'return', 'X-5,', 'Look', 'dealers', 'alpine', 'recalled', 'of', 'the', 'had', 'could', 'XFL,', 'defect', 'recalling', 'company', 'ZR,', 'for', 'received', 'release', 'ZP,', 'ZRJ,', 'X-7,', 'XG,', 'distributor', 'ski', 'said.', 'that', 'fix', 'authorized', 'are', 'a', 'no', 'Friday.', 'reported,', 'X-9,', 'to', 'spokesman', 'were', 'is', 'Dec.', '19—', 'cause', 'adjustment,', 'The', 'injuries', 'USA,', 'ZRC,', 'complaints', 'have', 'but', 'models', '13', 'asked', 'XF,', 'being', 'binding', 'French-made', 'bindings,', 'Vt.,', 'XH,', 'BURLINGTON,'}\n",
      "\n",
      "1.0: {'unexpectedly,'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subjs = defaultdict(set)\n",
    "\n",
    "for word in te.split():\n",
    "    sub = TextBlob(word).sentiment.subjectivity\n",
    "    subjs[sub].add(word)\n",
    "\n",
    "for sub in subjs:\n",
    "    print('{}: {}\\n'.format(sub, subjs[sub]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the article falls on the other extreme—extremely objective! All but one of the words has a subjectivity score of 0.0, yet the single word with a score of 1.0 (fittingly, 'unexpectedly') completely throws off the overall score. Playing around with some test strings, it looks like the sentiment algorithm entirely ignores words with score 0.0 (a score assigned to many, many words). One has to believe that with cases like the above, this can't be intended behavior. I believe TextBlob uses a wrapper of the sentiment analyzer from the `pattern` library, where the problem may lay. As it stands, I am currently unfamiliar with said library's codebase—perhaps a project for next week....\n",
    "\n",
    "The last part of this investigation involves training a model for identifying the year in which a given article was published. However, given that each data point is about 750 words long on average and I'm running this notebook on a laptop, nltk's algorithms were unsurprisingly unable to perform this classification task in a reasonable amount of time. I've decided to focus my modeling solely on the headlines for now.\n",
    "\n",
    "The most effective single-model option would probably be to implement a bag-of-words approach. It's likely that some words are much more common in 2017 headlines than 1987 headlines (eg. Trump, Russia, etc.), and vice versa (eg. Reagan, Soviet, etc.). I'm more interested in seeing if headline structure and style conventions have changed in the course of the past thirty years. One way to investigate this is to use part-of-speech tagging, which assigns each word in the text a tag which can be used as a feature for a machine learning algorithm. To link parts of speech to sentence structure, we can link adjacent tags together to form bigrams. In the following code, every bigram across the set of all headlines is cataloged and the 300 most common bigrams are pulled for use as binary features for each headline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_headlines = []\n",
    "for h in df_1987['headline']:\n",
    "    all_headlines.append((h, '1987'))\n",
    "for h in df_2017['headline']:\n",
    "    all_headlines.append((h, '2017'))\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+') # removes punctuation\n",
    "\n",
    "pos_bigrams = []\n",
    "for h in all_headlines:\n",
    "    tokenized = tokenizer.tokenize(h[0].lower())\n",
    "    pos_tagged = nltk.pos_tag(tokenized)\n",
    "    for i in range(len(pos_tagged) - 1):\n",
    "        pos_bigrams.append((pos_tagged[i][1], pos_tagged[i+1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "all_bigrams = nltk.FreqDist(pos_bigrams)\n",
    "common_bigrams_list = list(all_bigrams.most_common())[:300]\n",
    "bigram_features = [b[0] for b in common_bigrams_list]\n",
    "\n",
    "print(len(all_bigrams))\n",
    "print(len(bigram_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a feature vector must be generated for each headline, with each feature indicating the presence of a given part-of-speech bigram in the headline. The function `get_ngram_features()` constructs this vector for a given headline. A list comprehension is used to generate a list of tuples with the feature vector and year label for each headline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ngram_features(headline):\n",
    "    features = {}\n",
    "    tokenized = tokenizer.tokenize(headline.lower())\n",
    "    pos_tagged = nltk.pos_tag(tokenized)\n",
    "    \n",
    "    headline_bigrams = []\n",
    "    for i in range(len(pos_tagged) - 1):\n",
    "        headline_bigrams.append((pos_tagged[i][1], pos_tagged[i+1][1]))\n",
    "        \n",
    "    for b in bigram_features:\n",
    "        features['contains {}'.format(b)] = b in headline_bigrams\n",
    "        \n",
    "    return features\n",
    "\n",
    "featuresets = [(get_ngram_features(h), y) for (h,y) in all_headlines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the feature vectors and labels prepared, we can split the data into training and test sets and attempt classification. I chose to use a naive Bayes classifier, since it trains quickly and the part-of-speech bigrams convey word order information (alleviating a usual weakness of the algorithm—no understanding of word sequence). Since we have quite a bit of data on our hands (4000 headlines), much of it can be put aside for training; a 75:25 train:test split is used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.706"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle(featuresets)\n",
    "train, test = featuresets[:3000], featuresets[3000:]\n",
    "headline_clf = nltk.NaiveBayesClassifier.train(train)\n",
    "nltk.classify.accuracy(headline_clf, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that this is a binary classification problem, an accuracy of 0.706 isn't fantastic, but getting a moderate accuracy using only part-of-speech bigrams is pretty cool! We can use the show_most_informative_features() function to learn a bit more about the biggest differences between the two classes. (Note: shuffling and re-running the training can result in variations in accuracy of several percent, as well as different orderings of the most important features.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "   contains ('RB', 'CC') = True             2017 : 1987   =     10.1 : 1.0\n",
      "  contains ('RB', 'VBP') = True             2017 : 1987   =      9.4 : 1.0\n",
      "  contains ('WRB', 'JJ') = True             2017 : 1987   =      8.1 : 1.0\n",
      " contains ('VB', 'PRP$') = True             2017 : 1987   =      6.8 : 1.0\n",
      "  contains ('WRB', 'DT') = True             2017 : 1987   =      6.2 : 1.0\n",
      " contains ('VBG', 'PRP') = True             2017 : 1987   =      6.2 : 1.0\n",
      "  contains ('NNS', 'WP') = True             2017 : 1987   =      6.2 : 1.0\n",
      "   contains ('JJ', 'VB') = True             2017 : 1987   =      6.2 : 1.0\n",
      "  contains ('WP', 'VBD') = True             2017 : 1987   =      6.2 : 1.0\n",
      " contains ('VBZ', 'VBP') = True             2017 : 1987   =      6.2 : 1.0\n",
      "  contains ('CC', 'VBD') = True             2017 : 1987   =      5.7 : 1.0\n",
      "  contains ('PRP', 'IN') = True             2017 : 1987   =      4.9 : 1.0\n",
      " contains ('VBG', 'VBN') = True             2017 : 1987   =      4.2 : 1.0\n",
      "  contains ('PRP', 'VB') = True             2017 : 1987   =      4.2 : 1.0\n",
      "  contains ('NN', 'NNP') = True             2017 : 1987   =      4.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "headline_clf.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, nearly all of the most important features were found to be more prevalent in 2017 headlines than 1987 headlines; perhaps 1987 headlines tend to be more structurally uniform with regards to part-of-speech than 2017 headlines, hence the abundance of strong indicators of headlines written in 2017. On the other hand, we know that 2017 headlines are longer on average than 1987 headlines, so the skew may just be a reflection of the greater number of bigrams in 2017 headlines to begin with. We might be able to learn more if we can see the relevant headlines themselves.\n",
    "\n",
    "The part-of-speech bigrams themselves don't mean much when presented like this, but consulting [a list of the tags](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) helps make them a bit more sensible. More importantly, we should be able to use a bit of code to see them in context. This function prints all the headlines containing a given bigram, and capitalizes the words of first occurrence of that bigram. Let's try it out with the strongest feature, ('RB', 'CC')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987: o neill UP AND walking\n",
      "2017: cyprus reunification talks CLOSE BUT not close enough fail\n",
      "2017: a prague leader tries to bury a bodies exhibition ONCE AND for all\n",
      "2017: immigration moves FRONT AND center in italy s local elections\n",
      "2017: turks click AWAY BUT wikipedia is gone\n",
      "2017: obama s global visits inspire wistful comparisons of THEN AND now\n",
      "2017: RIGHT AND left react to the tensions with north korea\n",
      "2017: RIGHT AND left react to the justice dept s moves on affirmative action\n",
      "2017: RIGHT AND left on anthony scaramucci s dismissal and john f kelly s new role\n",
      "2017: RIGHT AND left on the russia sanctions and putin s response\n",
      "2017: RIGHT AND left react to kushner sessions and more\n",
      "2017: RIGHT AND left react to trump s interview health care and more\n",
      "2017: RIGHT AND left react to the donald trump jr email scandal\n",
      "2017: RIGHT AND left on the future of the senate health care bill\n",
      "2017: RIGHT AND left react to trump s norm defying tweets\n",
      "2017: trump warms to old idea kill health law NOW AND replace it later\n",
      "2017: RIGHT AND left react to the travel ban and other supreme court decisions\n",
      "2017: dreamers to stay in u s for NOW BUT long term fate is unclear\n",
      "2017: RIGHT AND left partisan writing you shouldn t miss\n",
      "2017: RIGHT AND left respond to trump s remarks on the london attacks\n",
      "2017: RIGHT AND left react to the paris climate agreement news\n",
      "2017: RIGHT AND left partisan writing you shouldn t miss\n"
     ]
    }
   ],
   "source": [
    "def print_feat_headlines(feat):\n",
    "    for h in all_headlines:\n",
    "        pos_bigrams = []\n",
    "        tokenized = tokenizer.tokenize(h[0].lower())\n",
    "        pos_tagged = nltk.pos_tag(tokenized)\n",
    "        for i in range(len(pos_tagged) - 1):\n",
    "            pos_bigrams.append((pos_tagged[i][1], pos_tagged[i+1][1]))\n",
    "        if feat in pos_bigrams:\n",
    "            idx = pos_bigrams.index(feat)\n",
    "            sp = tokenized\n",
    "            sp[idx] = sp[idx].upper()\n",
    "            sp[idx+1] = sp[idx+1].upper()\n",
    "            print('{}: {}'.format(h[1], ' '.join(sp)))\n",
    "\n",
    "print_feat_headlines(('RB', 'CC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops! A bunch of the 2017 headlines appear to just be entires in a series titled 'Right and Left', nonexistent in 1987. This isn't really the kind of insight I was hoping to glean from the model, so it would be good to remove the ('RB', 'CC') tag from the list of bigrams for the feature vectors and retrain the model. (As it turns out, the bigram corresponding to 'and left', ('CC', 'VBD'), is also skewing the model, so it's removed below as well.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298\n"
     ]
    }
   ],
   "source": [
    "avoid = [('RB', 'CC'), ('CC', 'VBD')]\n",
    "for a in avoid:\n",
    "    if a in bigram_features:\n",
    "        bigram_features.remove(a)\n",
    "        \n",
    "print(len(bigram_features))\n",
    "        \n",
    "featuresets = [(get_ngram_features(h), y) for (h,y) in all_headlines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.681"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle(featuresets)\n",
    "train, test = featuresets[:3000], featuresets[3000:]\n",
    "headline_clf = nltk.NaiveBayesClassifier.train(train)\n",
    "nltk.classify.accuracy(headline_clf, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As might be expected, the accuracy takes a bit of a hit, but now there might be more interesting differentiators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "  contains ('WP', 'VBZ') = True             2017 : 1987   =      9.1 : 1.0\n",
      "  contains ('WRB', 'JJ') = True             2017 : 1987   =      7.8 : 1.0\n",
      " contains ('VBG', 'PRP') = True             2017 : 1987   =      7.8 : 1.0\n",
      "  contains ('NNS', 'WP') = True             2017 : 1987   =      7.1 : 1.0\n",
      "  contains ('CC', 'PRP') = True             2017 : 1987   =      5.7 : 1.0\n",
      "  contains ('NN', 'PRP') = True             2017 : 1987   =      5.3 : 1.0\n",
      "  contains ('RB', 'PRP') = True             2017 : 1987   =      5.1 : 1.0\n",
      " contains ('VBZ', 'JJR') = True             2017 : 1987   =      5.1 : 1.0\n",
      "  contains ('VBN', 'RP') = True             2017 : 1987   =      5.1 : 1.0\n",
      "  contains ('PRP', 'IN') = True             2017 : 1987   =      5.1 : 1.0\n",
      "   contains ('RP', 'DT') = True             2017 : 1987   =      5.1 : 1.0\n",
      " contains ('PRP', 'VBP') = True             2017 : 1987   =      5.1 : 1.0\n",
      "  contains ('WP', 'VBD') = True             2017 : 1987   =      4.9 : 1.0\n",
      "  contains ('PRP', 'MD') = True             2017 : 1987   =      4.7 : 1.0\n",
      "   contains ('JJ', 'VB') = True             2017 : 1987   =      4.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "headline_clf.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the function written earlier to investigate some more of these bigrams in context. Let's start with the model's most useful bigram, ('WP', 'VBZ')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987: paris journal a french thinker WHO DECLINES a guru mantle\n",
      "1987: the questions begin WHO IS anthony kennedy\n",
      "1987: the emerging candidate WHO IS senator simon\n",
      "1987: bishop WHO SPEAKS for downtrodden\n",
      "2017: israel court rejects appeal for elor azaria soldier WHO SHOT wounded assailant\n",
      "2017: minneapolis police shooting of australian woman WHAT IS known so far\n",
      "2017: WHO PAYS for pell s day in court also cracks form in the gig economy\n",
      "2017: WHO WANTS to be king no one prince harry says\n",
      "2017: waiting in the wings in kansas WHO IS lt gov jeff colyer\n",
      "2017: WHO WANTS to run that mom and pop market almost no one\n",
      "2017: a patriotic fourth WHAT DOES that mean now\n",
      "2017: the criminals have been captured now WHO GETS the reward\n",
      "2017: WHO IS karen handel winner of the georgia special election\n",
      "2017: c b o head WHO PRIZES nonpartisanship finds work under g o p attack\n",
      "2017: WHO IS ralph northam virginia s democratic nominee for governor\n",
      "2017: WHO IS ed gillespie virginia s g o p nominee for governor\n",
      "2017: congress set to prod trump WHO DENIES russia meddled to punish moscow\n",
      "2017: WHO IS christopher wray trump s f b i pick is said to be low key and principled\n",
      "2017: embracing WHAT S natural\n"
     ]
    }
   ],
   "source": [
    "print_feat_headlines(('WP', 'VBZ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty interesting—a who-pronoun followed by a third-person singular present verb is a much more common construction in 2017 headlines. Perhaps this is linked to the increased length of headlines on average, giving more space for the kinds of compound sentences that would be likely to use this kind of structure. Also, there appears to be a new prevalence in 'Who ____?'-type headlines.\n",
    "\n",
    "Let's try looking at one more relevant bigram—('WRB', 'JJ')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987: washington talk census bureau HOW PROBLEMATIC the 1990 enumeration let us count the ways\n",
      "2017: HOW INDIA and china have come to the brink over a remote mountain pass\n",
      "2017: no jab no play HOW AUSTRALIA is handling the vaccination debate\n",
      "2017: WHEN YOUNG chinese ask what s your sign they don t mean dragon or rat\n",
      "2017: WHY UPROOTING corruption has plunged brazil into chaos\n",
      "2017: HOW MANY died in london fire anger rises as police won t say for sure\n",
      "2017: HOW CARDINAL pell rose to power trailed by a cloud of scandal\n",
      "2017: for macron s party in france success is broad but HOW DEEP\n",
      "2017: transcripts show HOW CONTENTIOUS trump s calls were with mexican and australian leaders\n",
      "2017: HOW SCHUMER held democrats together through a health care maelstrom\n",
      "2017: HOW U s military policy on transgender personnel changed under obama\n",
      "2017: HOW POEMS inspire pictures\n",
      "2017: HOW LOW can taxes go outside washington republicans find limits\n",
      "2017: HOW MICHAEL flynn s disdain for limits led to a legal quagmire\n",
      "2017: HOW G o p leaders came to view climate change as fake science\n"
     ]
    }
   ],
   "source": [
    "print_feat_headlines(('WRB', 'JJ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this seems to indicate a new 'kind' of headline: 'How ____'. This sort of headline conveys a more explanatory type of article, rather than a piece informing the reader of a specific newsworthy event. It seems that new conventions and standards in headline writing have come into place, perhaps as a result of more variety in the types of articles being published, as seen in this example. Further resolving these findings with the previous knowledge that headline lengths are actually less widely distributed today than in 1987 would be an interesting area of exploration.\n",
    "\n",
    "Lastly, given the apparent skewing in the important features towards bigrams present in 2017 headlines, it would be worthwhile to look at the precision and recall of the classifier to assess whether classification is skewed at all between the two categories. nltk includes these metrics, so finding the precision and recall can be accomplished as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.metrics.scores import precision, recall\n",
    "from collections import defaultdict\n",
    "\n",
    "refsets = defaultdict(set)\n",
    "testsets = defaultdict(set)\n",
    "\n",
    "for i, (feats, year) in enumerate(test):\n",
    "    refsets[year].add(i)\n",
    "    observed = headline_clf.classify(feats)\n",
    "    testsets[observed].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987 precision: 0.6610486891385767\n",
      "1987 recall: 0.7189409368635438\n",
      "2017 precision: 0.703862660944206\n",
      "2017 recall: 0.6444007858546169\n"
     ]
    }
   ],
   "source": [
    "print('1987 precision:', precision(refsets['1987'], testsets['1987']))\n",
    "print('1987 recall:', recall(refsets['1987'], testsets['1987']))\n",
    "print('2017 precision:', precision(refsets['2017'], testsets['2017']))\n",
    "print('2017 recall:', recall(refsets['2017'], testsets['2017']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The lower precision for 1987 headlines and lower recall for 2017 headlines indicate that the algorithm more often misclassifies 2017 headlines as 1987 headlines than vice versa. This is a bit surprising given that there seemed to be many strong indicators for 2017 headlines, which would imply that 2017 headlines were more likely to be classified correctly. However, the features that were investigated in detail only occurred in a small fraction of the headlines, so "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
